import os
import sys
import numpy as np
import pandas as pd
import time
import itertools
from src.utils.systems_collection import systems_collection
from src.utils.proged_utils import get_fit_settings, get_grammar_type
import ProGED as pg


def run_proged(systems, path_data, fname_data, iinit, eq_sym, snrs=[None, 30, 13], observability="full",
               use_default_library=False, path_out=".\\results\\check_proged\\",
               path_structures=".\\results\\proged\\structures\\", fname_structures="structures.csv"):

    """
    Run ProGED on the data generated by the function generate_data().

    Arguments:
        - systems             (list)                    list of <System> objects (see file system.py)
        - path_data           (string)                  path to the folder where the data is saved
        - fname_data          (string)                  name of the csv file with the data
        - iinit               (int)                     index of the initial condition to be used
        - eq_sym              (string)                  symbol of the equation to be identified
        - snrs                (list)                    list of desired Signal-to-Noise Ratios (in dB). If None (default),
                                                        no noise will be added, otherwise float or int values should be provided.
        - observability       (string)                  either 'full' or 'partial' (default = 'full')
        - path_out            (string)                  path to the folder where the results should be saved
        - use_default_library (bool)                    if True, the default library of functions is used for SINDy
                                                         (see pysindy documentation for details)

    Returns:
        Nothing. Results are saved in the folder specified by path_out.

    Example:
        Example run is shown at the end of the script.

    """

    for system_name in systems:
        for snr in snrs:

            print(f"{method} | {system_name} | snr: {snr} | init: {iinit} | batch: {ib} | eq: {eq_sym}")

            # Configure the model
            t1 = time.time()

            # get data (and organize it for proged)
            data_orig = pd.read_csv(f"{path_data}{system_name}{os.sep}{fname_data}".format(system_name, snr, iinit))
            data = data_orig[['t'] + systems[system_name].state_vars + ['d' + eq_sym]]

            # get structures
            systemBox = pg.ModelBox()
            systemBox.load(f"{path_structures}{fname_structures}{os.sep}{fname_structures}_b{ib}.pg")

            # settings for parameter estimation
            estimation_settings = get_fit_settings(obs=systems[system_name].state_vars)
            estimation_settings["parameter_estimation"]["param_bounds"] = (tuple(systems[system_name].param_bounds),)

            # go through every model in the systemBox dictionary and change lhs_vars to 'd' + eq_sym
            for model in range(len(systemBox)):
                systemBox[model].lhs_vars = ['d' + eq_sym]

            # parameter estimation
            systemBox_fitted = pg.fit_models(systemBox, data=data, settings=estimation_settings)

            # save the fitted models and the settings file
            os.makedirs( f"{path_out}{system_name}{os.sep}", exist_ok=True)
            out_filename = f"{method}_{exp_type}_{exp_version}_{system_name}_{data_type}_{data_size}_" \
                           f"snr{snr}_init{iinit}_obs{observability}_b{ib}_{eq_sym}_fitted.pg"
            systemBox_fitted.dump(f"{path_out}{system_name}{os.sep}{out_filename}")



def get_configuration(iinput, systems_collection, data_sizes, snrs, n_data, n_batches):

    # check if lorenz is in the keys of the systems_collection and adjust the combinations of state vars accordingly
    if 'lorenz' in systems_collection.keys():
        # remove lorenz from system_collection
        new_systems_collection = systems_collection.copy()
        lorenz = {'lorenz': new_systems_collection.pop('lorenz')}
        combinations_other = list(itertools.product(new_systems_collection, data_sizes, snrs, np.arange(n_data), np.arange(n_batches), ['x', 'y']))
        combinations_lorenz = list(itertools.product(lorenz, data_sizes, snrs, np.arange(n_data), np.arange(n_batches), ['x', 'y', 'z']))
        combinations = combinations_other + combinations_lorenz
    else:
        combinations = list(itertools.product(systems_collection, data_sizes, snrs, np.arange(n_data), np.arange(n_batches), ['x', 'y']))

    return combinations[iinput]

def get_configuration_from_unsuccessful(iinput, unsuccessful_configs_path):
    df = pd.read_csv(unsuccessful_configs_path, sep='\t')
    system_name = df.loc[iinput, 'system']
    data_size = df.loc[iinput, 'data_size']
    snr = int(df.loc[iinput, 'snr']) if not np.isnan(df.loc[iinput, 'snr']) else None
    iinit = df.loc[iinput, 'iinit']
    ib = df.loc[iinput, 'ib']
    eq_sym = df.loc[iinput, 'eq']
    return system_name, data_size, snr, iinit, ib, eq_sym

##
if __name__ == '__main__':

    # modifyable settings
    iinput = 0  # int(sys.argv[1])
    data_sizes = ["small", "large"]
    snrs = [None, 30, 13]   # [None, 30, 13]
    n_data = 4
    n_batches = 100
    n_samples = 2500

    # system_name, data_size, snr, iinit, ib, eq_sym = get_configuration(iinput, systems_collection, data_sizes,
    #                                                                    snrs, n_data, n_batches)
    root_dir = "D:\\Experiments\\symreg_methods_comparison"
    unsuccessful_configs_path = f"{root_dir}{os.sep}analysis{os.sep}sysident_num_full{os.sep}unsuccessfully_ran_models_proged" \
                                f"_e1_sysident_num_full.csv"
    system_name, data_size, snr, iinit, ib, eq_sym = get_configuration_from_unsuccessful(iinput, unsuccessful_configs_path)

    # fixed settings
    systems = {system_name: systems_collection[system_name]}
    method = "proged"
    exp_version = "e1"
    struct_version = "s1"
    observability = "full"
    exp_type = f"sysident_num_{observability}"
    data_type = "train"
    time_end = 20 if data_size == "large" else 10
    time_step = 0.01 if data_size == "large" else 0.1

    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    root_dir = "D:\\Experiments\\symreg_methods_comparison"
    # add root dir to the path
    sys.path.append(root_dir)

    path_data = f"{root_dir}{os.sep}data{os.sep}{data_type}{os.sep}{data_size}{os.sep}"
    fname_data = f"data_{{}}_len{time_end}_rate{str(time_step).replace('.', '')}_snr{{}}_init{{}}.csv"
    path_structures = f"{root_dir}{os.sep}results{os.sep}{exp_type}{os.sep}{method}{os.sep}structures{os.sep}"
    grammar_type = get_grammar_type(system_name)
    fname_structures = f"structs_{grammar_type}_nsamp{n_samples}_nbatch{n_batches}"
    path_out = f"{root_dir}{os.sep}results{os.sep}{exp_type}{os.sep}{method}{os.sep}{exp_version}{os.sep}"

    run_proged(systems=systems,
            path_data=path_data,
            fname_data=fname_data,
            iinit=iinit,
            eq_sym=eq_sym,
            snrs=[snr],
            observability=observability,
            use_default_library=False,
            path_out=path_out,
            path_structures=path_structures,
            fname_structures=fname_structures)
##

